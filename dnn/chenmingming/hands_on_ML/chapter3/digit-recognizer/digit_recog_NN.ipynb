{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# import keras\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "y_train_full = train['label']\n",
    "X_train_full = train.drop(['label'], axis=1)\n",
    "X_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:8000] / 255.0, X_train_full[8000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:8000], y_train_full[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.fromarray(np.uint8(np.array(X_train_full)[0].reshape(28,28)))\n",
    "# img.show()\n",
    "# print(np.uint8(np.array(X_train_full)[0].reshape(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DROP_OUT = 0.3\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(500, activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(DROP_OUT)) # dropout 正则化\n",
    "model.add(keras.layers.Dense(500, activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(DROP_OUT))\n",
    "model.add(keras.layers.Dense(500, activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(DROP_OUT))\n",
    "model.add(keras.layers.Dense(500, activation=\"relu\"))\n",
    "model.add(keras.layers.Dropout(DROP_OUT))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "# # keras.layers.Flatten(input_shape=[784]),\n",
    "# keras.layers.Dense(300, activation=\"relu\"),\n",
    "# keras.layers.Dense(100, activation=\"relu\"),\n",
    "# keras.layers.Dense(10, activation=\"softmax\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "WARNING:tensorflow:Layer dense_34 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.4423 - accuracy: 0.8575 - val_loss: 0.1674 - val_accuracy: 0.9488\n",
      "Epoch 2/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.1787 - accuracy: 0.9462 - val_loss: 0.1315 - val_accuracy: 0.9596\n",
      "Epoch 3/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.1389 - accuracy: 0.9583 - val_loss: 0.1191 - val_accuracy: 0.9615\n",
      "Epoch 4/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.1199 - accuracy: 0.9629 - val_loss: 0.1071 - val_accuracy: 0.9656\n",
      "Epoch 5/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.1083 - accuracy: 0.9658 - val_loss: 0.1026 - val_accuracy: 0.9685\n",
      "Epoch 6/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0967 - accuracy: 0.9704 - val_loss: 0.0993 - val_accuracy: 0.9681\n",
      "Epoch 7/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0905 - accuracy: 0.9722 - val_loss: 0.0972 - val_accuracy: 0.9695\n",
      "Epoch 8/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0820 - accuracy: 0.9744 - val_loss: 0.0961 - val_accuracy: 0.9707\n",
      "Epoch 9/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0787 - accuracy: 0.9761 - val_loss: 0.0929 - val_accuracy: 0.9718\n",
      "Epoch 10/250\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0746 - accuracy: 0.9765 - val_loss: 0.0944 - val_accuracy: 0.9705\n",
      "Epoch 11/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0715 - accuracy: 0.9782 - val_loss: 0.0916 - val_accuracy: 0.9722\n",
      "Epoch 12/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0683 - accuracy: 0.9788 - val_loss: 0.0912 - val_accuracy: 0.9732\n",
      "Epoch 13/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0648 - accuracy: 0.9799 - val_loss: 0.0907 - val_accuracy: 0.9734\n",
      "Epoch 14/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0635 - accuracy: 0.9804 - val_loss: 0.0895 - val_accuracy: 0.9734\n",
      "Epoch 15/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0591 - accuracy: 0.9816 - val_loss: 0.0892 - val_accuracy: 0.9740\n",
      "Epoch 16/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0597 - accuracy: 0.9813 - val_loss: 0.0895 - val_accuracy: 0.9737\n",
      "Epoch 17/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0579 - accuracy: 0.9822 - val_loss: 0.0895 - val_accuracy: 0.9743\n",
      "Epoch 18/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0569 - accuracy: 0.9826 - val_loss: 0.0883 - val_accuracy: 0.9750\n",
      "Epoch 19/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0540 - accuracy: 0.9829 - val_loss: 0.0880 - val_accuracy: 0.9755\n",
      "Epoch 20/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0539 - accuracy: 0.9827 - val_loss: 0.0874 - val_accuracy: 0.9747\n",
      "Epoch 21/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0522 - accuracy: 0.9834 - val_loss: 0.0877 - val_accuracy: 0.9747\n",
      "Epoch 22/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0501 - accuracy: 0.9840 - val_loss: 0.0872 - val_accuracy: 0.9756\n",
      "Epoch 23/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 0.0878 - val_accuracy: 0.9749\n",
      "Epoch 24/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0505 - accuracy: 0.9838 - val_loss: 0.0871 - val_accuracy: 0.9756\n",
      "Epoch 25/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0476 - accuracy: 0.9851 - val_loss: 0.0875 - val_accuracy: 0.9758\n",
      "Epoch 26/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0471 - accuracy: 0.9848 - val_loss: 0.0874 - val_accuracy: 0.9754\n",
      "Epoch 27/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.0871 - val_accuracy: 0.9753\n",
      "Epoch 28/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0459 - accuracy: 0.9854 - val_loss: 0.0872 - val_accuracy: 0.9762\n",
      "Epoch 29/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0446 - accuracy: 0.9858 - val_loss: 0.0874 - val_accuracy: 0.9759\n",
      "Epoch 30/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0436 - accuracy: 0.9858 - val_loss: 0.0862 - val_accuracy: 0.9762\n",
      "Epoch 31/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0437 - accuracy: 0.9867 - val_loss: 0.0874 - val_accuracy: 0.9766\n",
      "Epoch 32/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0411 - accuracy: 0.9871 - val_loss: 0.0871 - val_accuracy: 0.9764\n",
      "Epoch 33/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.0870 - val_accuracy: 0.9761\n",
      "Epoch 34/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0409 - accuracy: 0.9873 - val_loss: 0.0869 - val_accuracy: 0.9762\n",
      "Epoch 35/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 0.0870 - val_accuracy: 0.9762\n",
      "Epoch 36/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0869 - val_accuracy: 0.9764\n",
      "Epoch 37/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0869 - val_accuracy: 0.9761\n",
      "Epoch 38/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0389 - accuracy: 0.9871 - val_loss: 0.0875 - val_accuracy: 0.9759\n",
      "Epoch 39/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0400 - accuracy: 0.9870 - val_loss: 0.0873 - val_accuracy: 0.9764\n",
      "Epoch 40/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.0868 - val_accuracy: 0.9758\n",
      "Epoch 41/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.0874 - val_accuracy: 0.9762\n",
      "Epoch 42/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0357 - accuracy: 0.9887 - val_loss: 0.0875 - val_accuracy: 0.9761\n",
      "Epoch 43/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 0.0874 - val_accuracy: 0.9765\n",
      "Epoch 44/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.0879 - val_accuracy: 0.9765\n",
      "Epoch 45/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0870 - val_accuracy: 0.9759\n",
      "Epoch 46/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0352 - accuracy: 0.9889 - val_loss: 0.0881 - val_accuracy: 0.9760\n",
      "Epoch 47/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0352 - accuracy: 0.9887 - val_loss: 0.0880 - val_accuracy: 0.9764\n",
      "Epoch 48/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0351 - accuracy: 0.9888 - val_loss: 0.0876 - val_accuracy: 0.9765\n",
      "Epoch 49/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0358 - accuracy: 0.9879 - val_loss: 0.0874 - val_accuracy: 0.9765\n",
      "Epoch 50/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.0881 - val_accuracy: 0.9766\n",
      "Epoch 51/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0339 - accuracy: 0.9894 - val_loss: 0.0878 - val_accuracy: 0.9769\n",
      "Epoch 52/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0337 - accuracy: 0.9890 - val_loss: 0.0878 - val_accuracy: 0.9769\n",
      "Epoch 53/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 0.0878 - val_accuracy: 0.9772\n",
      "Epoch 54/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0321 - accuracy: 0.9891 - val_loss: 0.0877 - val_accuracy: 0.9769\n",
      "Epoch 55/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.0877 - val_accuracy: 0.9766\n",
      "Epoch 56/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0315 - accuracy: 0.9900 - val_loss: 0.0874 - val_accuracy: 0.9771\n",
      "Epoch 57/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0314 - accuracy: 0.9902 - val_loss: 0.0880 - val_accuracy: 0.9768\n",
      "Epoch 58/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0330 - accuracy: 0.9890 - val_loss: 0.0873 - val_accuracy: 0.9772\n",
      "Epoch 59/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0878 - val_accuracy: 0.9770\n",
      "Epoch 60/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 0.0882 - val_accuracy: 0.9772\n",
      "Epoch 61/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 0.0877 - val_accuracy: 0.9772\n",
      "Epoch 62/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0878 - val_accuracy: 0.9774\n",
      "Epoch 63/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0328 - accuracy: 0.9894 - val_loss: 0.0872 - val_accuracy: 0.9771\n",
      "Epoch 64/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0879 - val_accuracy: 0.9771\n",
      "Epoch 65/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0881 - val_accuracy: 0.9776\n",
      "Epoch 66/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.0877 - val_accuracy: 0.9768\n",
      "Epoch 67/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0878 - val_accuracy: 0.9774\n",
      "Epoch 68/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.0882 - val_accuracy: 0.9770\n",
      "Epoch 69/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0283 - accuracy: 0.9905 - val_loss: 0.0884 - val_accuracy: 0.9768\n",
      "Epoch 70/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0884 - val_accuracy: 0.9770\n",
      "Epoch 71/250\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0294 - accuracy: 0.9904 - val_loss: 0.0882 - val_accuracy: 0.9772\n",
      "Epoch 72/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 0.0886 - val_accuracy: 0.9766\n",
      "Epoch 73/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 0.0883 - val_accuracy: 0.9769\n",
      "Epoch 74/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0887 - val_accuracy: 0.9766\n",
      "Epoch 75/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 0.0890 - val_accuracy: 0.9766\n",
      "Epoch 76/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 0.0888 - val_accuracy: 0.9770\n",
      "Epoch 77/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0275 - accuracy: 0.9913 - val_loss: 0.0888 - val_accuracy: 0.9775\n",
      "Epoch 78/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0890 - val_accuracy: 0.9772\n",
      "Epoch 79/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.0890 - val_accuracy: 0.9770\n",
      "Epoch 80/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0253 - accuracy: 0.9921 - val_loss: 0.0883 - val_accuracy: 0.9768\n",
      "Epoch 81/250\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.0883 - val_accuracy: 0.9768\n",
      "Epoch 82/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0887 - val_accuracy: 0.9774\n",
      "Epoch 83/250\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0277 - accuracy: 0.9906 - val_loss: 0.0884 - val_accuracy: 0.9775\n",
      "Epoch 84/250\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.0886 - val_accuracy: 0.9774\n",
      "Epoch 85/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.0884 - val_accuracy: 0.9772\n",
      "Epoch 86/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0890 - val_accuracy: 0.9772\n",
      "Epoch 87/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.0893 - val_accuracy: 0.9770\n",
      "Epoch 88/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0895 - val_accuracy: 0.9772\n",
      "Epoch 89/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.0895 - val_accuracy: 0.9772\n",
      "Epoch 90/250\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0258 - accuracy: 0.9915 - val_loss: 0.0894 - val_accuracy: 0.9770\n",
      "Epoch 91/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0892 - val_accuracy: 0.9770\n",
      "Epoch 92/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.0899 - val_accuracy: 0.9768\n",
      "Epoch 93/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0894 - val_accuracy: 0.9769\n",
      "Epoch 94/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 0.0902 - val_accuracy: 0.9771\n",
      "Epoch 95/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 0.0896 - val_accuracy: 0.9770\n",
      "Epoch 96/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0235 - accuracy: 0.9926 - val_loss: 0.0894 - val_accuracy: 0.9768\n",
      "Epoch 97/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0889 - val_accuracy: 0.9771\n",
      "Epoch 98/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0246 - accuracy: 0.9923 - val_loss: 0.0888 - val_accuracy: 0.9771\n",
      "Epoch 99/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0888 - val_accuracy: 0.9774\n",
      "Epoch 100/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0892 - val_accuracy: 0.9775\n",
      "Epoch 101/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0892 - val_accuracy: 0.9771\n",
      "Epoch 102/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0893 - val_accuracy: 0.9775\n",
      "Epoch 103/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0897 - val_accuracy: 0.9776\n",
      "Epoch 104/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0896 - val_accuracy: 0.9775\n",
      "Epoch 105/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.0894 - val_accuracy: 0.9772\n",
      "Epoch 106/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0895 - val_accuracy: 0.9771\n",
      "Epoch 107/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0895 - val_accuracy: 0.9776\n",
      "Epoch 108/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0897 - val_accuracy: 0.9774\n",
      "Epoch 109/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0895 - val_accuracy: 0.9775\n",
      "Epoch 110/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0894 - val_accuracy: 0.9779\n",
      "Epoch 111/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.0895 - val_accuracy: 0.9776\n",
      "Epoch 112/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0894 - val_accuracy: 0.9774\n",
      "Epoch 113/250\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.0898 - val_accuracy: 0.9774\n",
      "Epoch 114/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
      "Epoch 115/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.0900 - val_accuracy: 0.9780\n",
      "Epoch 116/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0898 - val_accuracy: 0.9772\n",
      "Epoch 117/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.0893 - val_accuracy: 0.9772\n",
      "Epoch 118/250\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0895 - val_accuracy: 0.9771\n",
      "Epoch 119/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.0899 - val_accuracy: 0.9771\n",
      "Epoch 120/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.0898 - val_accuracy: 0.9772\n",
      "Epoch 121/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0898 - val_accuracy: 0.9771\n",
      "Epoch 122/250\n",
      "266/266 [==============================] - 5s 18ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0899 - val_accuracy: 0.9772\n",
      "Epoch 123/250\n",
      "266/266 [==============================] - 5s 20ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.0894 - val_accuracy: 0.9774\n",
      "Epoch 124/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0893 - val_accuracy: 0.9772\n",
      "Epoch 125/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0894 - val_accuracy: 0.9771\n",
      "Epoch 126/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0897 - val_accuracy: 0.9775\n",
      "Epoch 127/250\n",
      "266/266 [==============================] - 4s 16ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0898 - val_accuracy: 0.9776\n",
      "Epoch 128/250\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0900 - val_accuracy: 0.9776\n",
      "Epoch 129/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0896 - val_accuracy: 0.9775\n",
      "Epoch 130/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0897 - val_accuracy: 0.9774\n",
      "Epoch 131/250\n",
      "266/266 [==============================] - 5s 19ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0902 - val_accuracy: 0.9778\n",
      "Epoch 132/250\n",
      "266/266 [==============================] - 6s 21ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.0903 - val_accuracy: 0.9779\n",
      "Epoch 133/250\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0228 - accuracy: 0.9924 - val_loss: 0.0902 - val_accuracy: 0.9774\n",
      "Epoch 134/250\n",
      "266/266 [==============================] - 4s 17ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.0902 - val_accuracy: 0.9778\n",
      "Epoch 135/250\n",
      "266/266 [==============================] - 5s 17ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0903 - val_accuracy: 0.9774\n",
      "Epoch 136/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0229 - accuracy: 0.9925 - val_loss: 0.0903 - val_accuracy: 0.9770\n",
      "Epoch 137/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0218 - accuracy: 0.9934 - val_loss: 0.0903 - val_accuracy: 0.9774\n",
      "Epoch 138/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.0905 - val_accuracy: 0.9774\n",
      "Epoch 139/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0905 - val_accuracy: 0.9775\n",
      "Epoch 140/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.0906 - val_accuracy: 0.9778\n",
      "Epoch 141/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.0903 - val_accuracy: 0.9776\n",
      "Epoch 142/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0903 - val_accuracy: 0.9772\n",
      "Epoch 143/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0903 - val_accuracy: 0.9778\n",
      "Epoch 144/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0907 - val_accuracy: 0.9776\n",
      "Epoch 145/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0906 - val_accuracy: 0.9775\n",
      "Epoch 146/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0196 - accuracy: 0.9935 - val_loss: 0.0909 - val_accuracy: 0.9774\n",
      "Epoch 147/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0212 - accuracy: 0.9930 - val_loss: 0.0910 - val_accuracy: 0.9778\n",
      "Epoch 148/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0908 - val_accuracy: 0.9772\n",
      "Epoch 149/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0211 - accuracy: 0.9927 - val_loss: 0.0905 - val_accuracy: 0.9771\n",
      "Epoch 150/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0907 - val_accuracy: 0.9771\n",
      "Epoch 151/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0200 - accuracy: 0.9939 - val_loss: 0.0909 - val_accuracy: 0.9770\n",
      "Epoch 152/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0907 - val_accuracy: 0.9776\n",
      "Epoch 153/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.0906 - val_accuracy: 0.9775\n",
      "Epoch 154/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0906 - val_accuracy: 0.9776\n",
      "Epoch 155/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0906 - val_accuracy: 0.9775\n",
      "Epoch 156/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.0908 - val_accuracy: 0.9772\n",
      "Epoch 157/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0910 - val_accuracy: 0.9779\n",
      "Epoch 158/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0907 - val_accuracy: 0.9779\n",
      "Epoch 159/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0908 - val_accuracy: 0.9779\n",
      "Epoch 160/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0910 - val_accuracy: 0.9779\n",
      "Epoch 161/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0909 - val_accuracy: 0.9776\n",
      "Epoch 162/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0909 - val_accuracy: 0.9779\n",
      "Epoch 163/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.0908 - val_accuracy: 0.9780\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0910 - val_accuracy: 0.9778\n",
      "Epoch 165/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 0.0910 - val_accuracy: 0.9779\n",
      "Epoch 166/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0197 - accuracy: 0.9938 - val_loss: 0.0912 - val_accuracy: 0.9778\n",
      "Epoch 167/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0910 - val_accuracy: 0.9778\n",
      "Epoch 168/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0911 - val_accuracy: 0.9776\n",
      "Epoch 169/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.0912 - val_accuracy: 0.9774\n",
      "Epoch 170/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0908 - val_accuracy: 0.9772\n",
      "Epoch 171/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0912 - val_accuracy: 0.9774\n",
      "Epoch 172/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0913 - val_accuracy: 0.9775\n",
      "Epoch 173/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0910 - val_accuracy: 0.9774\n",
      "Epoch 174/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0910 - val_accuracy: 0.9775\n",
      "Epoch 175/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.0910 - val_accuracy: 0.9776\n",
      "Epoch 176/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
      "Epoch 177/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0911 - val_accuracy: 0.9779\n",
      "Epoch 178/250\n",
      "266/266 [==============================] - 4s 15ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0916 - val_accuracy: 0.9780\n",
      "Epoch 179/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0914 - val_accuracy: 0.9781\n",
      "Epoch 180/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0913 - val_accuracy: 0.9781\n",
      "Epoch 181/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0912 - val_accuracy: 0.9776\n",
      "Epoch 182/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.0909 - val_accuracy: 0.9775\n",
      "Epoch 183/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0911 - val_accuracy: 0.9778\n",
      "Epoch 184/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0913 - val_accuracy: 0.9778\n",
      "Epoch 185/250\n",
      "266/266 [==============================] - 4s 14ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0916 - val_accuracy: 0.9781\n",
      "Epoch 186/250\n",
      " 89/266 [=========>....................] - ETA: 2s - loss: 0.0195 - accuracy: 0.9939"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=250, batch_size=128,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, './model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "pred = y_pred.argmax(axis=1).reshape(-1)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_id = pd.Series(range(1,len(pred)+1))\n",
    "output = pd.DataFrame({'ImageId':image_id, 'Label':pred})\n",
    "output.to_csv(\"submission_NN.csv\",  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
