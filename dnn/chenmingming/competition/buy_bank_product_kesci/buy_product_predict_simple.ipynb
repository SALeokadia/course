{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.facecolor']=(1,1,1,1) # pycharm 绘图白底，看得清坐标\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train = pd.read_csv(\"./train_set.csv\")\n",
    "test = pd.read_csv(\"./test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-ced4426a5c6f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['default_'][data['default']=='yes'] = 1\n",
      "<ipython-input-40-ced4426a5c6f>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['housing_'][data['housing']=='yes'] = 1\n",
      "<ipython-input-40-ced4426a5c6f>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['loan_'][data['loan']=='yes'] = 1\n"
     ]
    }
   ],
   "source": [
    "# 对 'default','housing','loan' 3列二值(yes,no)特征转为 0，1\n",
    "def binaryFeature(data):\n",
    "    data['default_']=0\n",
    "    data['default_'][data['default']=='yes'] = 1\n",
    "    data['housing_']=0\n",
    "    data['housing_'][data['housing']=='yes'] = 1\n",
    "    data['loan_']=0\n",
    "    data['loan_'][data['loan']=='yes'] = 1\n",
    "    return data.drop(['default','housing','loan'], axis=1)\n",
    "\n",
    "X_train = binaryFeature(train)\n",
    "X_test = binaryFeature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['ID'], axis=1)\n",
    "X_test = X_test.drop(['ID'], axis=1)\n",
    "\n",
    "# 将训练集拆分一些出来做验证, 分层抽样\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splt = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "for train_idx, vaild_idx in splt.split(X_train, X_train['y']):\n",
    "    train_part = X_train.loc[train_idx]\n",
    "    valid_part = X_train.loc[vaild_idx]\n",
    "\n",
    "# 训练集拆成两部分 本地测试\n",
    "train_part_y = train_part['y']\n",
    "valid_part_y = valid_part['y']\n",
    "train_part = train_part.drop(['y'], axis=1)\n",
    "valid_part = valid_part.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def num_cat_splitor(X_train):\n",
    "    s = (X_train.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    num_cols = list(set(X_train.columns) - set(object_cols))\n",
    "    return num_cols, object_cols\n",
    "\n",
    "num_cols, object_cols = num_cat_splitor(X_train)\n",
    "num_cols.remove('y')\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_cols)),\n",
    "#         ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "#         ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(object_cols)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
    "    ])\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "{'model__leaf_size': 20, 'model__n_neighbors': 50}\n",
      "auc score:  0.8212356615336267\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "{'model__C': 1.2, 'model__max_iter': 10000, 'model__penalty': 'l2'}\n",
      "auc score:  0.9006649482666924\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   20.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# 本地测试，选模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression()\n",
    "svc = SVC(probability=True)\n",
    "gbdt = GradientBoostingClassifier()\n",
    "\n",
    "models = [knn, lr, svc, rf, gbdt]\n",
    "param_grid_list = [\n",
    "    # knn\n",
    "    [{\n",
    "        'model__n_neighbors' : [5,15,35,50,100],\n",
    "        'model__leaf_size' : [10,20,30,40,50]\n",
    "    }],\n",
    "    # lr\n",
    "    [{\n",
    "        'model__penalty' : ['l1', 'l2'],\n",
    "        'model__C' : [0.2, 0.5, 1, 1.2, 1.5],\n",
    "        'model__max_iter' : [10000]\n",
    "    }],\n",
    "    # svc\n",
    "    [{\n",
    "        'model__C' : [0.2, 0.5, 1, 1.2, 1.5],\n",
    "        'model__kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "\n",
    "    }],\n",
    "    # rf\n",
    "    [{\n",
    "    #     'preparation__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "        'model__n_estimators' : [150, 200,250,300,330,350],\n",
    "        'model__max_features' : [20,30,40,50, 60],\n",
    "        'model__max_depth' : [5,7,9]\n",
    "    }],\n",
    "    [{\n",
    "        'model__learning_rate' : [0.1, 0.5, 0.9],\n",
    "        'model__n_estimators' : [130, 150, 200, 300],\n",
    "        'model__max_features' : ['sqrt'],\n",
    "        'model__max_depth' : [5,7,9],\n",
    "        'model__min_samples_split' : [300,500,1000,1200,1500],\n",
    "        'model__min_samples_leaf' : [60, 100],\n",
    "        'model__subsample' : [0.8, 1]\n",
    "    }],\n",
    "]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    pipe = Pipeline([\n",
    "        ('preparation', full_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipe, param_grid_list[i], cv=3,\n",
    "                                    scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(train_part, train_part_y)\n",
    "    print(grid_search.best_params_)\n",
    "    final_model = grid_search.best_estimator_\n",
    "    pred = final_model.predict_proba(valid_part)[:,1] # roc 必须使用概率预测\n",
    "    print(\"auc score: \", roc_auc_score(valid_part_y, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier() \n",
      " finished!\n",
      "GradientBoostingClassifier(max_depth=5, max_features='sqrt',\n",
      "                           min_samples_leaf=60, min_samples_split=1200,\n",
      "                           n_estimators=130, random_state=10, subsample=0.8) \n",
      " finished!\n"
     ]
    }
   ],
   "source": [
    "# 全量训练，提交\n",
    "y_train = X_train['y']\n",
    "X_train = X_train.drop(['y'], axis=1)\n",
    "\n",
    "select_model = [rf, gbdt]\n",
    "\n",
    "for i, model in enumerate(select_model):\n",
    "    pipe = Pipeline([\n",
    "        ('preparation', full_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict_proba(X_test)[:,1] # roc 必须使用概率预测\n",
    "    print(model,'\\n finished!')\n",
    "    result = pd.DataFrame()\n",
    "    result['ID'] = test['ID']\n",
    "    result['pred'] = pred\n",
    "    result.to_csv('{}_pred.csv'.format(i), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}