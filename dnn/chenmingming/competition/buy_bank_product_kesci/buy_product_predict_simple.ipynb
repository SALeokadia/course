{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.facecolor']=(1,1,1,1) # pycharm 绘图白底，看得清坐标\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train = pd.read_csv(\"./train_set.csv\")\n",
    "test = pd.read_csv(\"./test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 将训练集拆分一些出来做验证, 分层抽样\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splt = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "for train_idx, vaild_idx in splt.split(train,train['y']):\n",
    "    train_part = train.loc[train_idx]\n",
    "    valid_part = train.loc[vaild_idx]\n",
    "    \n",
    "train_part_y = train_part['y']\n",
    "valid_part_y = valid_part['y']\n",
    "y_train = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-75-34e6b5587db4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['default_'][train['default']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['housing_'][train['housing']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['loan_'][train['loan']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['default_'][test['default']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['housing_'][test['housing']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['loan_'][test['loan']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_part['default_'][train_part['default']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_part['housing_'][train_part['housing']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_part['loan_'][train_part['loan']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_part['default_'][valid_part['default']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_part['housing_'][valid_part['housing']=='yes'] = 1\n",
      "<ipython-input-75-34e6b5587db4>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_part['loan_'][valid_part['loan']=='yes'] = 1\n"
     ]
    }
   ],
   "source": [
    "train['default_']=0\n",
    "train['default_'][train['default']=='yes'] = 1\n",
    "train['housing_']=0\n",
    "train['housing_'][train['housing']=='yes'] = 1\n",
    "train['loan_']=0\n",
    "train['loan_'][train['loan']=='yes'] = 1\n",
    "\n",
    "test['default_']=0\n",
    "test['default_'][test['default']=='yes'] = 1\n",
    "test['housing_']=0\n",
    "test['housing_'][test['housing']=='yes'] = 1\n",
    "test['loan_']=0\n",
    "test['loan_'][test['loan']=='yes'] = 1\n",
    "\n",
    "train_part['default_']=0\n",
    "train_part['default_'][train_part['default']=='yes'] = 1\n",
    "train_part['housing_']=0\n",
    "train_part['housing_'][train_part['housing']=='yes'] = 1\n",
    "train_part['loan_']=0\n",
    "train_part['loan_'][train_part['loan']=='yes'] = 1\n",
    "\n",
    "valid_part['default_']=0\n",
    "valid_part['default_'][valid_part['default']=='yes'] = 1\n",
    "valid_part['housing_']=0\n",
    "valid_part['housing_'][valid_part['housing']=='yes'] = 1\n",
    "valid_part['loan_']=0\n",
    "valid_part['loan_'][valid_part['loan']=='yes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['y' 'ID' 'default' 'housing' 'loan'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-78-a1d1f7489db2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mX_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'ID'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'default'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'housing'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'loan'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mtrain_part\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtrain_part\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'y'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'ID'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'default'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'housing'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'loan'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mvalid_part\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalid_part\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'y'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'ID'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'default'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'housing'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'loan'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36mdrop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   3988\u001B[0m                 \u001B[0mweight\u001B[0m  \u001B[1;36m1.0\u001B[0m     \u001B[1;36m0.8\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3989\u001B[0m         \"\"\"\n\u001B[1;32m-> 3990\u001B[1;33m         return super().drop(\n\u001B[0m\u001B[0;32m   3991\u001B[0m             \u001B[0mlabels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3992\u001B[0m             \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36mdrop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   3934\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;32min\u001B[0m \u001B[0maxes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3935\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3936\u001B[1;33m                 \u001B[0mobj\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_drop_axis\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3937\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3938\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0minplace\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m_drop_axis\u001B[1;34m(self, labels, axis, level, errors)\u001B[0m\n\u001B[0;32m   3968\u001B[0m                 \u001B[0mnew_axis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlevel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3969\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3970\u001B[1;33m                 \u001B[0mnew_axis\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0merrors\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3971\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0maxis_name\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnew_axis\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3972\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36mdrop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   5016\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5017\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0merrors\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m\"ignore\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5018\u001B[1;33m                 \u001B[1;32mraise\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{labels[mask]} not found in axis\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5019\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mindexer\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m~\u001B[0m\u001B[0mmask\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5020\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdelete\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mindexer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['y' 'ID' 'default' 'housing' 'loan'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['y','ID','default','housing','loan'], axis=1)\n",
    "X_test = test.drop(['ID','default','housing','loan'], axis=1)\n",
    "\n",
    "train_part = train_part.drop(['y','ID','default','housing','loan'], axis=1)\n",
    "valid_part = valid_part.drop(['y','ID','default','housing','loan'], axis=1)\n",
    "\n",
    "def num_cat_splitor(X_train):\n",
    "    s = (X_train.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    num_cols = list(set(X_train.columns) - set(object_cols))\n",
    "    return num_cols, object_cols\n",
    "num_cols, object_cols = num_cat_splitor(X_train)\n",
    "num_cols\n",
    "object_cols\n",
    "\n",
    "enc = OneHotEncoder(sparse=False,handle_unknown='ignore')\n",
    "enc.fit_transform(X_train[object_cols])\n",
    "arr = enc.transform(X_test[object_cols])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job_admin.' 'job_blue-collar' 'job_entrepreneur' 'job_housemaid'\n",
      " 'job_management' 'job_retired' 'job_self-employed' 'job_services'\n",
      " 'job_student' 'job_technician' 'job_unemployed' 'job_unknown'\n",
      " 'marital_divorced' 'marital_married' 'marital_single' 'education_primary'\n",
      " 'education_secondary' 'education_tertiary' 'education_unknown'\n",
      " 'contact_cellular' 'contact_telephone' 'contact_unknown' 'month_apr'\n",
      " 'month_aug' 'month_dec' 'month_feb' 'month_jan' 'month_jul' 'month_jun'\n",
      " 'month_mar' 'month_may' 'month_nov' 'month_oct' 'month_sep'\n",
      " 'poutcome_failure' 'poutcome_other' 'poutcome_success' 'poutcome_unknown']\n"
     ]
    }
   ],
   "source": [
    "fn = enc.get_feature_names(object_cols)\n",
    "print(fn)\n",
    "test_oh = pd.DataFrame(arr)\n",
    "test_oh.columns = fn\n",
    "test_oh['ID'] = test['ID']\n",
    "test_oh.to_csv('test_oh.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         job   marital  education  balance   contact  day month  \\\n",
      "0   43  management   married   tertiary      291   unknown    9   may   \n",
      "1   42  technician  divorced    primary     5076  cellular    7   apr   \n",
      "2   47      admin.   married  secondary      104  cellular   14   jul   \n",
      "3   28  management    single  secondary     -994  cellular   18   jul   \n",
      "4   42  technician  divorced  secondary     2974   unknown   21   may   \n",
      "\n",
      "   duration  campaign  pdays  previous poutcome  default_  housing_  loan_  \n",
      "0       150         2     -1         0  unknown         0         1      0  \n",
      "1        99         1    251         2    other         0         1      0  \n",
      "2        77         2     -1         0  unknown         0         1      1  \n",
      "3       174         2     -1         0  unknown         0         1      1  \n",
      "4       187         5     -1         0  unknown         0         1      0  \n",
      "[[1.500e+02 9.000e+00 4.300e+01 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [9.900e+01 7.000e+00 4.200e+01 ... 1.000e+00 0.000e+00 0.000e+00]\n",
      " [7.700e+01 1.400e+01 4.700e+01 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " ...\n",
      " [9.450e+02 1.300e+01 3.500e+01 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [1.164e+03 1.800e+01 3.700e+01 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [1.265e+03 1.900e+01 5.200e+01 ... 0.000e+00 0.000e+00 1.000e+00]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age         job   marital  education  balance   contact  day month  \\\n0   43  management   married   tertiary      291   unknown    9   may   \n1   42  technician  divorced    primary     5076  cellular    7   apr   \n2   47      admin.   married  secondary      104  cellular   14   jul   \n3   28  management    single  secondary     -994  cellular   18   jul   \n4   42  technician  divorced  secondary     2974   unknown   21   may   \n\n   duration  campaign  pdays  previous poutcome  default_  housing_  loan_  \n0       150         2     -1         0  unknown         0         1      0  \n1        99         1    251         2    other         0         1      0  \n2        77         2     -1         0  unknown         0         1      1  \n3       174         2     -1         0  unknown         0         1      1  \n4       187         5     -1         0  unknown         0         1      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>balance</th>\n      <th>contact</th>\n      <th>day</th>\n      <th>month</th>\n      <th>duration</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>default_</th>\n      <th>housing_</th>\n      <th>loan_</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>43</td>\n      <td>management</td>\n      <td>married</td>\n      <td>tertiary</td>\n      <td>291</td>\n      <td>unknown</td>\n      <td>9</td>\n      <td>may</td>\n      <td>150</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>42</td>\n      <td>technician</td>\n      <td>divorced</td>\n      <td>primary</td>\n      <td>5076</td>\n      <td>cellular</td>\n      <td>7</td>\n      <td>apr</td>\n      <td>99</td>\n      <td>1</td>\n      <td>251</td>\n      <td>2</td>\n      <td>other</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>secondary</td>\n      <td>104</td>\n      <td>cellular</td>\n      <td>14</td>\n      <td>jul</td>\n      <td>77</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>management</td>\n      <td>single</td>\n      <td>secondary</td>\n      <td>-994</td>\n      <td>cellular</td>\n      <td>18</td>\n      <td>jul</td>\n      <td>174</td>\n      <td>2</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>42</td>\n      <td>technician</td>\n      <td>divorced</td>\n      <td>secondary</td>\n      <td>2974</td>\n      <td>unknown</td>\n      <td>21</td>\n      <td>may</td>\n      <td>187</td>\n      <td>5</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>unknown</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "        \n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_cols)),\n",
    "#         ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "#         ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(object_cols)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False,handle_unknown='ignore')),\n",
    "    ])\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "print(X_train.head(5))\n",
    "X_prepared = full_pipeline.fit_transform(X_train)\n",
    "print(X_prepared)\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=300)\n",
      "auc score:  0.6945770681235798\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-66-dbacf77d0aed>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[1;33m(\u001B[0m\u001B[1;34m'model'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m     ])\n\u001B[1;32m---> 24\u001B[1;33m     \u001B[0mprepare_select_and_predict_pipeline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_part\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtrain_part_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m     \u001B[0mpred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mprepare_select_and_predict_pipeline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalid_part\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     26\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\sklearn\\pipeline.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    333\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_final_estimator\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m'passthrough'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    334\u001B[0m                 \u001B[0mfit_params_last_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfit_params_steps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 335\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_final_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params_last_step\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    336\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    337\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, monitor)\u001B[0m\n\u001B[0;32m    496\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    497\u001B[0m         \u001B[1;31m# fit the boosting stages\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 498\u001B[1;33m         n_stages = self._fit_stages(\n\u001B[0m\u001B[0;32m    499\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mraw_predictions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_rng\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    500\u001B[0m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001B[0m in \u001B[0;36m_fit_stages\u001B[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m             \u001B[1;31m# fit next stage of trees\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 555\u001B[1;33m             raw_predictions = self._fit_stage(\n\u001B[0m\u001B[0;32m    556\u001B[0m                 \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mraw_predictions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    557\u001B[0m                 random_state, X_idx_sorted, X_csc, X_csr)\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001B[0m in \u001B[0;36m_fit_stage\u001B[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mX\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX_csr\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mX_csr\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001B[0m\u001B[0;32m    212\u001B[0m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001B[0;32m    213\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m   1240\u001B[0m         \"\"\"\n\u001B[0;32m   1241\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1242\u001B[1;33m         super().fit(\n\u001B[0m\u001B[0;32m   1243\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1244\u001B[0m             \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32md:\\program files\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001B[0m\n\u001B[0;32m    373\u001B[0m                                            min_impurity_split)\n\u001B[0;32m    374\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 375\u001B[1;33m         \u001B[0mbuilder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtree_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_idx_sorted\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    376\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    377\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_outputs_\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "perceptron = Perceptron()\n",
    "rf = RandomForestClassifier(n_estimators=300)\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "gbdt = GradientBoostingClassifier(learning_rate=0.1, n_estimators=130, max_features='sqrt', max_depth=5, min_samples_split=1200, min_samples_leaf=60, subsample=0.8, random_state=10)\n",
    "\n",
    "# models = [perceptron, rf, knn, lr, svc]\n",
    "models = [rf, gbdt]\n",
    "\n",
    "for model in models:\n",
    "    prepare_select_and_predict_pipeline = Pipeline([\n",
    "        ('preparation', full_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    prepare_select_and_predict_pipeline.fit(train_part,train_part_y)\n",
    "    pred = prepare_select_and_predict_pipeline.predict(valid_part)\n",
    "    print(model)\n",
    "    print(\"auc score: \", roc_auc_score(valid_part_y, pred))\n",
    "\n",
    "    # param_grid = [{\n",
    "    # #     'preparation__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "    #     'model__n_estimators' : [250,300,330,350,400,500],\n",
    "    #     'model__max_features':[5,10,20,30,50]\n",
    "    # }]\n",
    "\n",
    "    # grid_search_prep = GridSearchCV(prepare_select_and_predict_pipeline, param_grid, cv=3,\n",
    "    #                                 scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "    # grid_search_prep.fit(train_part, train_part_y)\n",
    "    # grid_search_prep.best_params_\n",
    "    # final_model = grid_search_prep.best_estimator_\n",
    "    # y_pred_test = final_model.predict(valid_part)\n",
    "    # print(\"auc score: \", roc_auc_score(valid_part_y, y_pred_test))\n",
    "    #\n",
    "#     result = pd.DataFrame()\n",
    "#     result['ID'] = test['ID']\n",
    "#     result['pred'] = y_pred_test\n",
    "#     result.to_csv('buy_product_pred.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}