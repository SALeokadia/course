{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.facecolor']=(1,1,1,1) # pycharm 绘图白底，看得清坐标\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train = pd.read_csv(\"./train_set.csv\")\n",
    "test = pd.read_csv(\"./test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mingm\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\mingm\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\mingm\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 对 'default','housing','loan' 3列二值(yes,no)特征转为 0，1\n",
    "def binaryFeature(data):\n",
    "    data['default_']=0\n",
    "    data['default_'][data['default']=='yes'] = 1\n",
    "    data['housing_']=0\n",
    "    data['housing_'][data['housing']=='yes'] = 1\n",
    "    data['loan_']=0\n",
    "    data['loan_'][data['loan']=='yes'] = 1\n",
    "    return data.drop(['default','housing','loan'], axis=1)\n",
    "\n",
    "X_train = binaryFeature(train)\n",
    "X_test = binaryFeature(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['ID'], axis=1)\n",
    "X_test = X_test.drop(['ID'], axis=1)\n",
    "\n",
    "# 将训练集拆分一些出来做验证, 分层抽样\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "splt = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1)\n",
    "for train_idx, vaild_idx in splt.split(X_train, X_train['y']):\n",
    "    train_part = X_train.loc[train_idx]\n",
    "    valid_part = X_train.loc[vaild_idx]\n",
    "\n",
    "# 训练集拆成两部分 本地测试\n",
    "train_part_y = train_part['y']\n",
    "valid_part_y = valid_part['y']\n",
    "train_part = train_part.drop(['y'], axis=1)\n",
    "valid_part = valid_part.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def num_cat_splitor(X_train):\n",
    "    s = (X_train.dtypes == 'object')\n",
    "    object_cols = list(s[s].index)\n",
    "    num_cols = list(set(X_train.columns) - set(object_cols))\n",
    "    return num_cols, object_cols\n",
    "\n",
    "num_cols, object_cols = num_cat_splitor(X_train)\n",
    "num_cols.remove('y')\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_cols)),\n",
    "#         ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "#         ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(object_cols)),\n",
    "        ('cat_encoder', OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
    "    ])\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# 本地测试，选模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression()\n",
    "svc = SVC(probability=True)\n",
    "gbdt = GradientBoostingClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = [knn, lr, svc, rf, gbdt]\n",
    "param_grid_list = [\n",
    "    # knn\n",
    "    [{\n",
    "        'model__n_neighbors' : [5,15,35,50,100],\n",
    "        'model__leaf_size' : [10,20,30,40,50]\n",
    "    }],\n",
    "    # lr\n",
    "    [{\n",
    "        'model__penalty' : ['l1', 'l2'],\n",
    "        'model__C' : [0.2, 0.5, 1, 1.2, 1.5],\n",
    "        'model__max_iter' : [10000]\n",
    "    }],\n",
    "    # svc\n",
    "    [{\n",
    "        'model__C' : [0.2, 0.5, 1, 1.2],\n",
    "        'model__kernel' : ['rbf']\n",
    "    }],\n",
    "    # rf\n",
    "    [{\n",
    "    #     'preparation__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "        'model__n_estimators' : [200,250,300,330,350],\n",
    "        'model__max_features' : [20,30,40,50],\n",
    "        'model__max_depth' : [5,7]\n",
    "    }],\n",
    "    # gbdt\n",
    "    [{\n",
    "        'model__learning_rate' : [0.1, 0.5],\n",
    "        'model__n_estimators' : [130, 200, 300],\n",
    "        'model__max_features' : ['sqrt'],\n",
    "        'model__max_depth' : [5,7],\n",
    "        'model__min_samples_split' : [500,1000,1200],\n",
    "        'model__min_samples_leaf' : [60, 100],\n",
    "        'model__subsample' : [0.8, 1]\n",
    "    }],\n",
    "]\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    pipe = Pipeline([\n",
    "        ('preparation', full_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipe, param_grid_list[i], cv=3,\n",
    "                                    scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(train_part, train_part_y)\n",
    "    print(grid_search.best_params_)\n",
    "    final_model = grid_search.best_estimator_\n",
    "    pred = final_model.predict_proba(valid_part)[:,1] # roc 必须使用概率预测\n",
    "    print(\"auc score: \", roc_auc_score(valid_part_y, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 全量训练，网格搜索参数，提交\n",
    "y_train = X_train['y']\n",
    "X_train_ = X_train.drop(['y'], axis=1)\n",
    "\n",
    "select_model = [rf, gbdt]\n",
    "param_grid_list = [\n",
    "    # rf\n",
    "    [{\n",
    "    #     'preparation__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "        'model__n_estimators' : [250,300,350,400],\n",
    "        'model__max_features' : [7,8,10,15,20],\n",
    "        'model__max_depth' : [7,9,10,11]\n",
    "    }],\n",
    "    # gbdt\n",
    "    [{\n",
    "        'model__learning_rate' : [0.03, 0.05, 0.1],\n",
    "        'model__n_estimators' : [200, 300, 350],\n",
    "        'model__max_features' : ['sqrt'],\n",
    "        'model__max_depth' : [7,9,11],\n",
    "        'model__min_samples_split' : [300, 400, 500],\n",
    "        'model__min_samples_leaf' : [50,60,70],\n",
    "        'model__subsample' : [0.8, 1, 1.2]\n",
    "    }],\n",
    "]\n",
    "\n",
    "for i, model in enumerate(select_model):\n",
    "    pipe = Pipeline([\n",
    "        ('preparation', full_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipe, param_grid_list[i], cv=3,\n",
    "                                    scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train_, y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    final_model = grid_search.best_estimator_\n",
    "    pred = final_model.predict_proba(X_test)[:,1] # roc 必须使用概率预测\n",
    "    print(model,'\\n finished!')\n",
    "    result = pd.DataFrame()\n",
    "    result['ID'] = test['ID']\n",
    "    result['pred'] = pred\n",
    "    result.to_csv('{}_pred.csv'.format(i), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.8min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-e5788fa4dbf7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     33\u001B[0m     rand_search = RandomizedSearchCV(pipe, param_distributions=param_distribs[i], cv=3,\n\u001B[0;32m     34\u001B[0m                                     n_iter=20,scoring='roc_auc', verbose=2, n_jobs=-1)\n\u001B[1;32m---> 35\u001B[1;33m     \u001B[0mrand_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     36\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrand_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_params_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[0mfinal_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrand_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbest_estimator_\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     71\u001B[0m                           FutureWarning)\n\u001B[0;32m     72\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 73\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     74\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     75\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    734\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    735\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 736\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    737\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    738\u001B[0m         \u001B[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1529\u001B[0m         evaluate_candidates(ParameterSampler(\n\u001B[0;32m   1530\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_distributions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_iter\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1531\u001B[1;33m             random_state=self.random_state))\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params)\u001B[0m\n\u001B[0;32m    713\u001B[0m                                \u001B[1;32mfor\u001B[0m \u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    714\u001B[0m                                in product(candidate_params,\n\u001B[1;32m--> 715\u001B[1;33m                                           cv.split(X, y, groups)))\n\u001B[0m\u001B[0;32m    716\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    717\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1040\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1041\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1042\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1043\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1044\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    919\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    920\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 921\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    922\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    923\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[0;32m    541\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    425\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    426\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 427\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    428\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    429\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\program files\\python37\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    294\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m    \u001B[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 296\u001B[1;33m                 \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    297\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 随机搜索参数\n",
    "y_train = X_train['y']\n",
    "X_train_ = X_train.drop(['y'], axis=1)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "select_model = [rf, gbdt]\n",
    "param_distribs = [\n",
    "    # rf\n",
    "    [{\n",
    "    #     'preparation__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "        'model__n_estimators' : randint(low=250, high=500),\n",
    "        'model__max_features' : randint(low=10, high=30),\n",
    "        'model__max_depth' : randint(low=8, high=20)\n",
    "    }],\n",
    "    # gbdt\n",
    "    [{\n",
    "        'model__learning_rate' : np.linspace(0.01, 0.1, 10),\n",
    "        'model__n_estimators' : randint(low=250, high=500),\n",
    "        'model__max_features' : ['sqrt'],\n",
    "        'model__max_depth' : randint(low=8, high=20),\n",
    "        'model__min_samples_split' : randint(low=400, high=1000),\n",
    "        'model__min_samples_leaf' : randint(low=40, high=80),\n",
    "        'model__subsample' : np.linspace(0.5, 1.5, 10)\n",
    "    }],\n",
    "]\n",
    "\n",
    "for i, model in enumerate(select_model):\n",
    "    pipe = Pipeline([\n",
    "        ('preparation', full_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    rand_search = RandomizedSearchCV(pipe, param_distributions=param_distribs[i], cv=3,\n",
    "                                    n_iter=20,scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "    rand_search.fit(X_train_, y_train)\n",
    "    print(rand_search.best_params_)\n",
    "    final_model = rand_search.best_estimator_\n",
    "    pred = final_model.predict_proba(X_test)[:,1] # roc 必须使用概率预测\n",
    "    print(model,'\\n finished!')\n",
    "    result = pd.DataFrame()\n",
    "    result['ID'] = test['ID']\n",
    "    result['pred'] = pred\n",
    "    result.to_csv('{}_pred.csv'.format(i), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "{'model__max_depth': 9, 'model__max_features': 10, 'model__n_estimators': 300}\n",
      "RandomForestClassifier() \n",
      " finished!\n",
      "Fitting 3 folds for each of 486 candidates, totalling 1458 fits\n",
      "{'model__learning_rate': 0.05, 'model__max_depth': 9, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 60, 'model__min_samples_split': 400, 'model__n_estimators': 300, 'model__subsample': 1}\n",
      "GradientBoostingClassifier() \n",
      " finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 11.5min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 997 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1442 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1458 out of 1458 | elapsed: 24.3min finished\n"
     ]
    }
   ],
   "source": [
    "# 全量训练，提交\n",
    "y_train = X_train['y']\n",
    "X_train_ = X_train.drop(['y'], axis=1)\n",
    "\n",
    "select_model = [rf, gbdt]\n",
    "param_grid_list = [\n",
    "    # rf\n",
    "    [{\n",
    "    #     'preparation__num_pipeline__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
    "        'model__n_estimators' : [250,300,350,400],\n",
    "        'model__max_features' : [10,15,20,30,40],\n",
    "        'model__max_depth' : [5,7,9]\n",
    "    }],\n",
    "    # gbdt\n",
    "    [{\n",
    "        'model__learning_rate' : [0.05, 0.1, 0.2],\n",
    "        'model__n_estimators' : [130, 200, 300],\n",
    "        'model__max_features' : ['sqrt'],\n",
    "        'model__max_depth' : [5,7,9],\n",
    "        'model__min_samples_split' : [400, 500,1000],\n",
    "        'model__min_samples_leaf' : [50,60],\n",
    "        'model__subsample' : [0.8, 1, 1.2]\n",
    "    }],\n",
    "]\n",
    "\n",
    "for i, model in enumerate(select_model):\n",
    "    pipe = Pipeline([\n",
    "        ('preparation', full_pipeline),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    grid_search = GridSearchCV(pipe, param_grid_list[i], cv=3,\n",
    "                                    scoring='roc_auc', verbose=2, n_jobs=-1)\n",
    "    grid_search.fit(X_train_, y_train)\n",
    "    print(grid_search.best_params_)\n",
    "    final_model = grid_search.best_estimator_\n",
    "    pred = final_model.predict_proba(X_test)[:,1] # roc 必须使用概率预测\n",
    "    print(model,'\\n finished!')\n",
    "    result = pd.DataFrame()\n",
    "    result['ID'] = test['ID']\n",
    "    result['pred'] = pred\n",
    "    result.to_csv('{}_pred.csv'.format(i), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}